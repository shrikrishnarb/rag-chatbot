from langchain_openai import ChatOpenAI
from langchain.schema import HumanMessage
import os
from dotenv import load_dotenv

load_dotenv()

llm = ChatOpenAI(model="gpt-3.5-turbo", temperature=0.7)

print("ðŸ§  Ask me anything (type 'exit' to quit):")
while True:
    user_input = input("You: ")
    if user_input.lower() in ['exit', 'quit']:
        print("ðŸ‘‹ Goodbye!")
        break

    response = llm.invoke([HumanMessage(content=user_input)])
    print("AI:", response.content)
